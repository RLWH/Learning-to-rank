{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to rank notebook\n",
    "\n",
    "Reference:   \n",
    "[1] [From RankNet to LambdaRank to LambdaMART: An Overview](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.180.634&rep=rep1&type=pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSLR10KDataset(Dataset):\n",
    "    \"\"\"MSLR 10K Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pairs (list of tuples): The pairs of record to be compared\n",
    "            scores (list of int): The scores of 1, -1, 0\n",
    "            i_features (list of list): Feature list of ith document\n",
    "            j_features (list of list): Feature list of jth document\n",
    "        \"\"\"\n",
    "        \n",
    "        self.path = path\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        self.query_ids = []\n",
    "        \n",
    "        # Generate dataset\n",
    "        self._get_format_data(self.path)\n",
    "        self.pairs, self.scores, self.i_features, self.j_features = \\\n",
    "            self._get_pair_doc_data(self.labels, self.query_ids)\n",
    "        \n",
    "\n",
    "    def _get_format_data(self, data_path):\n",
    "        \"\"\"\n",
    "        Extract data from data path\n",
    "        Args:\n",
    "            data_path (str): Path of the data file\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Getting data from %s\" % data_path)\n",
    "        \n",
    "        def _extract_features(toks):\n",
    "            \"\"\"Extract features from tokens (e.g. 1: 0 -> 0)\"\"\"\n",
    "            features = []\n",
    "            for tok in toks:\n",
    "                features.append(float(tok.split(\":\")[1]))\n",
    "            return features\n",
    "\n",
    "        def _extract_query_data(tok):\n",
    "            \"\"\"Extract query features (e.g. qid: 10 -> 10)\"\"\"\n",
    "            # qid\n",
    "            query_features = [tok.split(\":\")[1]]\n",
    "            return query_features\n",
    "        \n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data, _, comment = line.rstrip().partition(\"#\")\n",
    "                toks = data.split()\n",
    "\n",
    "                self.labels.append(int(toks[0]))                  # label - The relevance score\n",
    "                self.features.append(_extract_features(toks[2:]))    # doc features\n",
    "                self.query_ids.append(_extract_query_data(toks[1]))  # qid\n",
    "                \n",
    "    def _get_pair_doc_data(self, y_train, query_id):\n",
    "        \"\"\"\n",
    "        Get pairs data\n",
    "        Args:\n",
    "            y_train (list): List of relevance score\n",
    "            query_id (list): List of query_id\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        scores = []\n",
    "        i_features = []\n",
    "        j_features = []\n",
    "\n",
    "        for i in range(0, len(query_id) - 1):\n",
    "            for j in range(i + 1, len(query_id)):\n",
    "\n",
    "                # Make sure the documents are for the same query id\n",
    "                if query_id[i][0] != query_id[j][0]:\n",
    "                    break\n",
    "\n",
    "                if y_train[i] > y_train[j]:\n",
    "                    pairs.append((i, j))\n",
    "                    i_features.append(self.features[i])\n",
    "                    j_features.append(self.features[j])\n",
    "                    scores.append(1)\n",
    "                elif y_train[i] < y_train[j]:\n",
    "                    pairs.append((j, i))\n",
    "                    i_features.append(self.features[j])\n",
    "                    j_features.append(self.features[i])\n",
    "                    scores.append(1)\n",
    "                else:\n",
    "                    pairs.append((i, j))\n",
    "                    i_features.append(self.features[i])\n",
    "                    j_features.append(self.features[j])\n",
    "                    scores.append(0)\n",
    "\n",
    "        return pairs, scores, i_features, j_features\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.query_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample = {\"pairs\": self.pairs[idx],\n",
    "                  \"i_features\": torch.tensor(np.array(self.i_features[idx])),\n",
    "                  \"j_features\": torch.tensor(np.array(self.j_features[idx])),\n",
    "                  \"scores\": torch.tensor(self.scores[idx])}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MSLR10KDataset(path=\"./data/MSLR-WEB10K/Fold1/train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(nn.Module):\n",
    "    \"\"\"Pairwise Ranking Ranknet\"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, hidden_size_1=32, hidden_size_2=16):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(nn.Linear(num_features, hidden_size_1),\n",
    "                                   nn.Dropout(0.5),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_size_1, hidden_size_2),\n",
    "                                   nn.Dropout(0.5),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_size_2, 1))\n",
    "        self.output = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_i, input_j):\n",
    "        si = self.model(input_i)\n",
    "        sj = self.model(input_j)\n",
    "        diff = si - sj\n",
    "        prob = self.output(diff)\n",
    "        return prob\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet = RankNet(num_features=136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(ranknet.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    \n",
    "    # Load dataloader\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, sample_batched in enumerate(dataloader):\n",
    "        pair_index = sample_batched[\"pairs\"]\n",
    "        i_features = sample_batched[\"i_features\"].float()\n",
    "        j_features = sample_batched[\"j_features\"].float()\n",
    "        labels = sample_batched[\"scores\"].view(-1, 1).float()\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = ranknet.forward(i_features, j_features)\n",
    "#         print(outputs.grad_fn)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print(ranknet.model.parameters)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            # print every 2000 iterations\n",
    "#             print(list(ranknet.parameters())[0])\n",
    "            print(\"\\r[%d, %5d] loss: %.3f\" % (epoch + 1,\n",
    "                                              i + 1,\n",
    "                                              running_loss / 100), end=\"\")\n",
    "            running_loss = 0.0\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
