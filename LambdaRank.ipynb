{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LambdaRank Implementation in PyTorch\n",
    "\n",
    "### Key formulation of LambdaRank\n",
    "\n",
    "Formulation of pairwise ranking, for document $i$ and $j$ - Ranknet Loss function  \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "L(y, s) &= \\sum_{i=1}^{n}\\sum_{j=1}^{n}\\mathop{\\mathbb{I}_{y_i > y_j}} \\log_2(1 + e^{-\\sigma(s_i - s_j)}) \\\\\n",
    "& = \\sum_{y_i > y_j} \\log_2(1+e^{-\\sigma(s_i - s_j)})\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "#### Ranking Metrics - NDGC\n",
    "\\begin{equation}\n",
    "\\text{NDCG} = \\frac{1}{\\text{maxDCG}} \\sum_{i=1}^{n} \\frac{2^{y_i} - 1}{\\log_2(1+i)} = \\sum_{i=1}^{n}\\frac{G_i}{D_i}\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "G_i = \\frac{2^{y_i} - 1}{\\text{maxDCG}}, D_i = \\log_2(1+i)\n",
    "\\end{equation}\n",
    "\n",
    "- $G_i$ is the gain function\n",
    "- $D_i$ is the discount functions\n",
    "- $\\text{maxDCG}$ is a constant factor per query\n",
    "\n",
    "#### LambdaRank - Dynamically adjust the loss function during the training based on ranking metrics\n",
    "\n",
    "Define the change of NDCG\n",
    "\\begin{equation}\n",
    "\\Delta\\text{NDCG}(i,j) = |G_i - G_j||\\frac{1}{D_i} -  \\frac{1}{D_j}|\n",
    "\\end{equation}\n",
    "\n",
    "Loss function\n",
    "\\begin{equation}\n",
    "L(y,s) = \\sum_{y_i>y_j}\\Delta\\text{NDCG}(i,j) log_2(1+e^{-\\sigma(s_i-s_j)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSLR10KDataset(Dataset):\n",
    "    \"\"\"MSLR 10K Pairs Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, path, mode=\"single\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str)\n",
    "            mode (str), \"single\" or \"pairs\"\n",
    "        \"\"\"\n",
    "        \n",
    "        assert mode in [\"single\", \"pairs\"]\n",
    "        \n",
    "        print(\"Mode: %s\" % mode)\n",
    "        \n",
    "        self.path = path\n",
    "        self.mode = mode\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        self.query_ids = []\n",
    "        \n",
    "        # Generate dataset\n",
    "        self._get_format_data(self.path)\n",
    "        \n",
    "        if mode == \"pairs\":\n",
    "            self.pairs, self.scores, self.i_features, self.j_features, self.i_labels, self.j_labels = \\\n",
    "                self._get_pair_doc_data(self.labels, self.query_ids)\n",
    "        \n",
    "\n",
    "    def _get_format_data(self, data_path):\n",
    "        \"\"\"\n",
    "        Extract data from data path\n",
    "        Args:\n",
    "            data_path (str): Path of the data file\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Getting data from %s\" % data_path)\n",
    "        \n",
    "        def _extract_features(toks):\n",
    "            \"\"\"Extract features from tokens (e.g. 1: 0 -> 0)\"\"\"\n",
    "            features = []\n",
    "            for tok in toks:\n",
    "                features.append(float(tok.split(\":\")[1]))\n",
    "            return features\n",
    "\n",
    "        def _extract_query_data(tok):\n",
    "            \"\"\"Extract query features (e.g. qid: 10 -> 10)\"\"\"\n",
    "            # qid\n",
    "            query_features = [tok.split(\":\")[1]]\n",
    "            return query_features\n",
    "        \n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data, _, comment = line.rstrip().partition(\"#\")\n",
    "                toks = data.split()\n",
    "\n",
    "                self.labels.append(int(toks[0]))                  # label - The relevance score\n",
    "                self.features.append(_extract_features(toks[2:]))    # doc features\n",
    "                self.query_ids.append(_extract_query_data(toks[1]))  # qid\n",
    "                \n",
    "    def _get_pair_doc_data(self, y_train, query_id):\n",
    "        \"\"\"\n",
    "        Get pairs data\n",
    "        Args:\n",
    "            y_train (list): List of relevance score\n",
    "            query_id (list): List of query_id\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        scores = []\n",
    "        i_features = []\n",
    "        j_features = []\n",
    "        i_labels = []\n",
    "        j_labels = []\n",
    "\n",
    "        for i in range(0, len(query_id) - 1):\n",
    "            for j in range(i + 1, len(query_id)):\n",
    "\n",
    "                # Make sure the documents are for the same query id\n",
    "                if query_id[i][0] != query_id[j][0]:\n",
    "                    break\n",
    "\n",
    "                if y_train[i] > y_train[j]:\n",
    "                    pairs.append((i, j))\n",
    "                    i_features.append(self.features[i])\n",
    "                    j_features.append(self.features[j])\n",
    "                    i_labels.append(y_train[i])\n",
    "                    j_labels.append(y_train[j])\n",
    "                    scores.append(1)\n",
    "                elif y_train[i] < y_train[j]:\n",
    "                    pairs.append((j, i))\n",
    "                    i_features.append(self.features[j])\n",
    "                    j_features.append(self.features[i])\n",
    "                    i_labels.append(y_train[j])\n",
    "                    j_labels.append(y_train[i])\n",
    "                    scores.append(1)\n",
    "                else:\n",
    "                    pairs.append((i, j))\n",
    "                    i_features.append(self.features[i])\n",
    "                    j_features.append(self.features[j])\n",
    "                    i_labels.append(y_train[i])\n",
    "                    j_labels.append(y_train[j])\n",
    "                    scores.append(0)\n",
    "\n",
    "        return pairs, scores, i_features, j_features, i_labels, j_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.query_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        if self.mode == \"pairs\":\n",
    "            sample = {\"pairs\": self.pairs[idx],\n",
    "                      \"i_features\": torch.tensor(np.array(self.i_features[idx])),\n",
    "                      \"j_features\": torch.tensor(np.array(self.j_features[idx])),\n",
    "                      \"i_label\": torch.tensor(np.array(self.i_labels[idx])),\n",
    "                      \"j_label\": torch.tensor(np.array(self.j_labels[idx])),\n",
    "                      \"scores\": torch.tensor(self.scores[idx])}\n",
    "        elif self.mode == \"single\":\n",
    "            sample = {\"idx\": torch.tensor(np.array(idx), dtype=torch.float),\n",
    "                      \"features\": torch.tensor(np.array(self.features[idx]), dtype=torch.float),\n",
    "                      \"label\": torch.tensor(np.array(self.labels[idx]), dtype=torch.float)}\n",
    "        else:\n",
    "            raise ValueError(\"Mode should be either single or pairs\")\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: single\n",
      "Getting data from ./data/MSLR-WEB10K/Fold1/train.txt\n"
     ]
    }
   ],
   "source": [
    "dataset = MSLR10KDataset(path=\"./data/MSLR-WEB10K/Fold1/train.txt\", mode=\"single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "723412"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: pairs\n",
      "Getting data from ./data/MSLR-WEB10K/Fold1/train.txt\n"
     ]
    }
   ],
   "source": [
    "pairs_dataset = MSLR10KDataset(path=\"./data/MSLR-WEB10K/Fold1/train.txt\", mode=\"pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "723412"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pairs': (0, 1),\n",
       " 'i_features': tensor([ 3.0000e+00,  3.0000e+00,  0.0000e+00,  0.0000e+00,  3.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          1.5600e+02,  4.0000e+00,  0.0000e+00,  7.0000e+00,  1.6700e+02,\n",
       "          6.9313e+00,  2.2077e+01,  1.9673e+01,  2.2255e+01,  6.9266e+00,\n",
       "          3.0000e+00,  3.0000e+00,  0.0000e+00,  0.0000e+00,  6.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  2.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  2.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  2.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          1.9231e-02,  7.5000e-01,  0.0000e+00,  0.0000e+00,  3.5928e-02,\n",
       "          6.4100e-03,  2.5000e-01,  0.0000e+00,  0.0000e+00,  1.1976e-02,\n",
       "          6.4100e-03,  2.5000e-01,  0.0000e+00,  0.0000e+00,  1.1976e-02,\n",
       "          6.4100e-03,  2.5000e-01,  0.0000e+00,  0.0000e+00,  1.1976e-02,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          6.9313e+00,  2.2077e+01,  0.0000e+00,  0.0000e+00,  1.3853e+01,\n",
       "          1.1521e+00,  5.9925e+00,  0.0000e+00,  0.0000e+00,  2.2972e+00,\n",
       "          3.0789e+00,  8.5173e+00,  0.0000e+00,  0.0000e+00,  6.1566e+00,\n",
       "          2.3104e+00,  7.3590e+00,  0.0000e+00,  0.0000e+00,  4.6177e+00,\n",
       "          6.9473e-01,  1.0842e+00,  0.0000e+00,  0.0000e+00,  2.7879e+00,\n",
       "          1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          1.2941e+01,  2.0593e+01,  0.0000e+00,  0.0000e+00,  1.6767e+01,\n",
       "         -1.8568e+01, -7.7601e+00, -2.0839e+01, -2.5436e+01, -1.4519e+01,\n",
       "         -2.1710e+01, -2.1340e+01, -2.4498e+01, -2.7690e+01, -2.0204e+01,\n",
       "         -1.5449e+01, -4.4745e+00, -2.3635e+01, -2.8120e+01, -1.3582e+01,\n",
       "          3.0000e+00,  6.2000e+01,  1.1090e+07,  2.0000e+00,  1.1600e+02,\n",
       "          6.4034e+04,  1.3000e+01,  3.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00], dtype=torch.float64),\n",
       " 'j_features': tensor([ 3.0000e+00,  0.0000e+00,  3.0000e+00,  0.0000e+00,  3.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          4.0600e+02,  0.0000e+00,  5.0000e+00,  5.0000e+00,  4.1600e+02,\n",
       "          6.9313e+00,  2.2077e+01,  1.9673e+01,  2.2255e+01,  6.9266e+00,\n",
       "          2.8000e+01,  0.0000e+00,  3.0000e+00,  0.0000e+00,  3.1000e+01,\n",
       "          8.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  9.0000e+00,\n",
       "          1.0000e+01,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.1000e+01,\n",
       "          9.3333e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0333e+01,\n",
       "          8.8889e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.8889e-01,\n",
       "          6.8966e-02,  0.0000e+00,  6.0000e-01,  0.0000e+00,  7.4519e-02,\n",
       "          1.9704e-02,  0.0000e+00,  2.0000e-01,  0.0000e+00,  2.1635e-02,\n",
       "          2.4631e-02,  0.0000e+00,  2.0000e-01,  0.0000e+00,  2.6442e-02,\n",
       "          2.2989e-02,  0.0000e+00,  2.0000e-01,  0.0000e+00,  2.4840e-02,\n",
       "          5.0000e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.0000e-06,\n",
       "          6.3912e+01,  0.0000e+00,  1.9673e+01,  0.0000e+00,  7.0793e+01,\n",
       "          1.1521e+01,  0.0000e+00,  5.3732e+00,  0.0000e+00,  1.2635e+01,\n",
       "          3.0789e+01,  0.0000e+00,  7.9858e+00,  0.0000e+00,  3.3861e+01,\n",
       "          2.1304e+01,  0.0000e+00,  6.5578e+00,  0.0000e+00,  2.3598e+01,\n",
       "          6.1920e+01,  0.0000e+00,  1.1672e+00,  0.0000e+00,  7.5340e+01,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          9.9443e-01,  0.0000e+00,  1.0000e+00,  0.0000e+00,  9.9545e-01,\n",
       "          2.0885e+01,  0.0000e+00,  2.4233e+01,  0.0000e+00,  2.1162e+01,\n",
       "         -1.1556e+01, -2.1242e+01, -8.4290e+00, -2.5436e+01, -1.1298e+01,\n",
       "         -1.6487e+01, -2.4805e+01, -2.1461e+01, -2.7690e+01, -1.6209e+01,\n",
       "         -1.1646e+01, -2.4041e+01, -5.1439e+00, -2.8120e+01, -1.1411e+01,\n",
       "          2.0000e+00,  5.4000e+01,  1.1090e+07,  2.0000e+00,  1.2400e+02,\n",
       "          6.4034e+04,  1.0000e+00,  2.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00], dtype=torch.float64),\n",
       " 'i_label': tensor(2),\n",
       " 'j_label': tensor(2),\n",
       " 'scores': tensor(0)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=8,\n",
    "                        shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = len(dataset[0]['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 136])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(sample_batched[\"features\"].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the model\n",
    "\n",
    "Reference: https://github.com/airalcorn2/RankNet/blob/master/lambdarank.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(nn.Module):\n",
    "    \"\"\"Pairwise Ranking Ranknet\"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, hidden_size_1=32, hidden_size_2=16):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(nn.Linear(num_features, hidden_size_1),\n",
    "                                   nn.Dropout(0.5),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_size_1, hidden_size_2),\n",
    "                                   nn.Dropout(0.5),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_size_2, 1))\n",
    "        self.output = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_i, input_j):\n",
    "        si = self.model(input_i)\n",
    "        sj = self.model(input_j)\n",
    "        diff = si - sj\n",
    "        prob = self.output(diff)\n",
    "        return prob\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet = RankNet(NUM_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores\n",
    "doc_features = dataset[0]['features']\n",
    "doc_scores = ranknet.predict(doc_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-104588.7656], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_tensors(t):\n",
    "    rank = torch.zeros(8)\n",
    "    sorted_values, idx = torch.sort(t, dim=0, descending=True)\n",
    "    rank[idx] = 1 + torch.arange(t.size()[0]).float().view(-1, 1)\n",
    "    print(rank.shape)\n",
    "    return sorted_values, idx, rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dcg(scores, labels):\n",
    "    \"\"\"\n",
    "    Calculate DCG\n",
    "    \n",
    "    Args:\n",
    "        scores (torch.Tensor)\n",
    "    \"\"\"\n",
    "    sorted_scores, rank = rank_tensors(scores)\n",
    "    relevance = labels\n",
    "    \n",
    "    print(sorted_scores)\n",
    "    print(rank)\n",
    "    print(relevance)\n",
    "    \n",
    "    nom = (2 ** relevance) - 1\n",
    "    denom = torch.log2(rank.float() + 1)\n",
    "    \n",
    "    return torch.sum(nom/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_scores ->  tensor([ 4.1295e+03,  1.3244e+03,  1.2197e-01, -3.7664e+01,  7.1668e+02,\n",
      "        -1.4218e+02, -5.2687e+02,  5.0729e+02], grad_fn=<AsStridedBackward>)\n",
      "doc_relevance_labels ->  tensor([1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "torch.Size([8])\n",
      "sorted_scores ->  tensor([ 4.1295e+03,  1.3244e+03,  7.1668e+02,  5.0729e+02,  1.2197e-01,\n",
      "        -3.7664e+01, -1.4218e+02, -5.2687e+02], grad_fn=<AsStridedBackward>)\n",
      "sorted_labels ->  tensor([1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "scores_ranking -> tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "dcg ->  tensor(2.4464)\n",
      "torch.Size([8])\n",
      "sorted_true_labels ->  tensor([1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "sorted_true_labels_idx ->  tensor([0, 1, 4, 6, 2, 3, 5, 7])\n",
      "scores_ranking -> tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "max_dcg ->  tensor(2.5616)\n",
      "ndcg ->  tensor(0.9550)\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    doc_features = sample_batched['features']\n",
    "    doc_relevance_labels = sample_batched['label']\n",
    "    doc_scores = ranknet.predict(doc_features)\n",
    "    \n",
    "    print(\"doc_scores -> \", doc_scores.flatten())\n",
    "    print(\"doc_relevance_labels -> \", doc_relevance_labels.flatten())\n",
    "    \n",
    "    # 1. Get the ranking of the scores\n",
    "    sorted_scores, sorted_scores_idx, _ = rank_tensors(doc_scores)\n",
    "    scores_ranking = 1 + torch.arange(doc_scores.size()[0])\n",
    "    sorted_labels = doc_relevance_labels[sorted_scores_idx]\n",
    "    print(\"sorted_scores -> \", sorted_scores.flatten())\n",
    "    print(\"sorted_labels -> \", sorted_labels.flatten())\n",
    "    print(\"scores_ranking ->\", scores_ranking.flatten())\n",
    "    \n",
    "    dcg = torch.sum(((2 ** sorted_labels) - 1) / torch.log2(1 + scores_ranking.float().view(-1, 1)))\n",
    "    print(\"dcg -> \", dcg)\n",
    "    \n",
    "    # Max dcg\n",
    "    sorted_true_labels, sorted_true_labels_idx, _ = rank_tensors(doc_relevance_labels.view(-1, 1))\n",
    "    print(\"sorted_true_labels -> \", sorted_true_labels.flatten())\n",
    "    print(\"sorted_true_labels_idx -> \", sorted_true_labels_idx.flatten())\n",
    "    print(\"scores_ranking ->\", scores_ranking.flatten())\n",
    "    \n",
    "    max_dcg = torch.sum(((2 ** sorted_true_labels) - 1) / torch.log2(1 + scores_ranking.float().view(-1, 1)))\n",
    "    print(\"max_dcg -> \", max_dcg)\n",
    "    \n",
    "    ndcg = dcg / max_dcg\n",
    "    print(\"ndcg -> \", ndcg)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_ndcg(i, j, i_labels, j_labels):\n",
    "    \"\"\"\n",
    "    Calculate the delta of NDCG\n",
    "    Args:\n",
    "        i: i scores\n",
    "        j: j scores\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
