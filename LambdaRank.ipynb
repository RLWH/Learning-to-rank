{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LambdaRank Implementation in PyTorch\n",
    "\n",
    "### Key formulation of LambdaRank\n",
    "\n",
    "Formulation of pairwise ranking, for document $i$ and $j$ - Ranknet Loss function  \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "L(y, s) &= \\sum_{i=1}^{n}\\sum_{j=1}^{n}\\mathop{\\mathbb{I}_{y_i > y_j}} \\log_2(1 + e^{-\\sigma(s_i - s_j)}) \\\\\n",
    "& = \\sum_{y_i > y_j} \\log_2(1+e^{-\\sigma(s_i - s_j)})\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "#### Ranking Metrics - NDGC\n",
    "\\begin{equation}\n",
    "\\text{NDCG} = \\frac{1}{\\text{maxDCG}} \\sum_{i=1}^{n} \\frac{2^{y_i} - 1}{\\log_2(1+i)} = \\sum_{i=1}^{n}\\frac{G_i}{D_i}\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "G_i = \\frac{2^{y_i} - 1}{\\text{maxDCG}}, D_i = \\log_2(1+i)\n",
    "\\end{equation}\n",
    "\n",
    "- $G_i$ is the gain function\n",
    "- $D_i$ is the discount functions\n",
    "- $\\text{maxDCG}$ is a constant factor per query\n",
    "\n",
    "#### LambdaRank - Dynamically adjust the loss function during the training based on ranking metrics\n",
    "\n",
    "Define the change of NDCG\n",
    "\\begin{equation}\n",
    "\\Delta\\text{NDCG}(i,j) = |G_i - G_j||\\frac{1}{D_i} -  \\frac{1}{D_j}|\n",
    "\\end{equation}\n",
    "\n",
    "Loss function\n",
    "\\begin{equation}\n",
    "L(y,s) = \\sum_{y_i>y_j}\\Delta\\text{NDCG}(i,j) log_2(1+e^{-\\sigma(s_i-s_j)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSLR10KDataset(Dataset):\n",
    "    \"\"\"MSLR 10K Pairs Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pairs (list of tuples): The pairs of record to be compared\n",
    "            scores (list of int): The scores of 1, -1, 0\n",
    "            i_features (list of list): Feature list of ith document\n",
    "            j_features (list of list): Feature list of jth document\n",
    "        \"\"\"\n",
    "        \n",
    "        self.path = path\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        self.query_ids = []\n",
    "        \n",
    "        # Generate dataset\n",
    "        self._get_format_data(self.path)\n",
    "        self.pairs, self.scores, self.i_features, self.j_features = \\\n",
    "            self._get_pair_doc_data(self.labels, self.query_ids)\n",
    "        \n",
    "\n",
    "    def _get_format_data(self, data_path):\n",
    "        \"\"\"\n",
    "        Extract data from data path\n",
    "        Args:\n",
    "            data_path (str): Path of the data file\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Getting data from %s\" % data_path)\n",
    "        \n",
    "        def _extract_features(toks):\n",
    "            \"\"\"Extract features from tokens (e.g. 1: 0 -> 0)\"\"\"\n",
    "            features = []\n",
    "            for tok in toks:\n",
    "                features.append(float(tok.split(\":\")[1]))\n",
    "            return features\n",
    "\n",
    "        def _extract_query_data(tok):\n",
    "            \"\"\"Extract query features (e.g. qid: 10 -> 10)\"\"\"\n",
    "            # qid\n",
    "            query_features = [tok.split(\":\")[1]]\n",
    "            return query_features\n",
    "        \n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data, _, comment = line.rstrip().partition(\"#\")\n",
    "                toks = data.split()\n",
    "\n",
    "                self.labels.append(int(toks[0]))                  # label - The relevance score\n",
    "                self.features.append(_extract_features(toks[2:]))    # doc features\n",
    "                self.query_ids.append(_extract_query_data(toks[1]))  # qid\n",
    "                \n",
    "    def _get_pair_doc_data(self, y_train, query_id):\n",
    "        \"\"\"\n",
    "        Get pairs data\n",
    "        Args:\n",
    "            y_train (list): List of relevance score\n",
    "            query_id (list): List of query_id\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        scores = []\n",
    "        i_features = []\n",
    "        j_features = []\n",
    "\n",
    "        for i in range(0, len(query_id) - 1):\n",
    "            for j in range(i + 1, len(query_id)):\n",
    "\n",
    "                # Make sure the documents are for the same query id\n",
    "                if query_id[i][0] != query_id[j][0]:\n",
    "                    break\n",
    "\n",
    "                if y_train[i] > y_train[j]:\n",
    "                    pairs.append((i, j))\n",
    "                    i_features.append(self.features[i])\n",
    "                    j_features.append(self.features[j])\n",
    "                    scores.append(1)\n",
    "                elif y_train[i] < y_train[j]:\n",
    "                    pairs.append((j, i))\n",
    "                    i_features.append(self.features[j])\n",
    "                    j_features.append(self.features[i])\n",
    "                    scores.append(1)\n",
    "                else:\n",
    "                    pairs.append((i, j))\n",
    "                    i_features.append(self.features[i])\n",
    "                    j_features.append(self.features[j])\n",
    "                    scores.append(0)\n",
    "\n",
    "        return pairs, scores, i_features, j_features\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.query_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample = {\"pairs\": self.pairs[idx],\n",
    "                  \"i_features\": torch.tensor(np.array(self.i_features[idx])),\n",
    "                  \"j_features\": torch.tensor(np.array(self.j_features[idx])),\n",
    "                  \"scores\": torch.tensor(self.scores[idx])}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from ./data/MSLR-WEB10K/Fold1/train.txt\n"
     ]
    }
   ],
   "source": [
    "dataset = MSLR10KDataset(path=\"./data/MSLR-WEB10K/Fold1/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = len(dataset[0]['i_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the model\n",
    "\n",
    "Reference: https://github.com/airalcorn2/RankNet/blob/master/lambdarank.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(nn.Module):\n",
    "    \"\"\"Pairwise Ranking Ranknet\"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, hidden_size_1=32, hidden_size_2=16):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(nn.Linear(num_features, hidden_size_1),\n",
    "                                   nn.Dropout(0.5),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_size_1, hidden_size_2),\n",
    "                                   nn.Dropout(0.5),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(hidden_size_2, 1))\n",
    "        self.output = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_i, input_j):\n",
    "        si = self.model(input_i)\n",
    "        sj = self.model(input_j)\n",
    "        diff = si - sj\n",
    "        prob = self.output(diff)\n",
    "        return prob\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet = RankNet(NUM_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores\n",
    "doc_features = dataset[0]['i_features']\n",
    "doc_scores = ranknet.predict(doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Document rank\n",
    "sorted_scores, rank = doc_scores.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discount function\n",
    "D_fcn = torch.log2(1 + rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(scores):\n",
    "    \"\"\"\n",
    "    Calculate DCG\n",
    "    \n",
    "    Args:\n",
    "        scores (torch.Tensor)\n",
    "    \"\"\"\n",
    "    sorted_scores, rank = scores.sort()\n",
    "    \n",
    "    nom = (2 ** scores) - 1\n",
    "    denom = torch.log2(rank + 1)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
